# 大文件上传实现方案

## 基本概念

大文件上传主要解决以下问题：
- 上传大文件时浏览器可能崩溃
- 上传过程中断后需要重新上传
- 服务器处理大文件时可能超时
- 网络波动导致上传失败

## 实现思路

### 核心技术点
1. **文件分片**：将大文件切分成固定大小的小块
2. **断点续传**：记录已上传的分片，支持中断后继续上传
3. **文件秒传**：通过文件hash验证，避免重复上传相同文件
4. **分片验证**：验证分片的完整性和正确性
5. **分片合并**：所有分片上传完成后，服务端合并为完整文件

## 简单版流程

```
前端                                    后端
  |                                      |
  |--- 选择文件 -----------------------> |
  |                                      |
  |--- 文件分片 -----------------------> |
  |                                      |
  |--- 上传分片1 ----------------------> |--- 保存分片1
  |                                      |
  |--- 上传分片2 ----------------------> |--- 保存分片2
  |                                      |
  |--- 上传分片N ----------------------> |--- 保存分片N
  |                                      |
  |--- 请求合并文件 -------------------> |--- 合并所有分片
  |                                      |
  |<-- 返回文件URL或存储路径 ----------- |
  |                                      |
```

## 完整版流程

```
前端                                    后端
  |                                      |
  |--- 选择文件 -----------------------> |
  |                                      |
  |--- 计算文件MD5/hash ---------------> |
  |                                      |
  |--- 发送文件hash验证请求 -----------> |--- 检查文件是否已存在
  |                                      |
  |<-- 返回验证结果和已上传分片信息 ---- |
  |    (如果文件已存在则秒传完成)        |
  |                                      |
  |--- 文件分片 -----------------------> |
  |                                      |
  |--- 并行上传分片1 ------------------> |--- 保存分片1
  |    (带有文件hash+分片索引)           |    (验证分片有效性)
  |                                      |
  |--- 并行上传分片2 ------------------> |--- 保存分片2
  |                                      |    (验证分片有效性)
  |                                      |
  |    ... (多个分片并行上传) ...        |
  |                                      |
  |--- 监控上传进度 --------------------> |
  |                                      |
  |--- 出错重试特定分片 ---------------> |
  |                                      |
  |--- 请求合并文件 -------------------> |--- 验证所有分片完整性
  |    (带有文件hash)                   |
  |                                      |--- 合并所有分片
  |                                      |
  |                                      |--- 删除临时分片
  |                                      |
  |<-- 返回文件URL和存储路径 ----------- |
  |                                      |
```

## 前端实现（mall-admin）

### 技术选型
- 使用 `SparkMD5` 库计算文件 hash
- 使用 `File API` 进行文件分片
- 使用 `axios` 进行请求发送和上传
- 使用 `Promise.all` 或 `async/await` 管理并发上传

### 实现步骤

1. **文件选择与分片**
```typescript
// 示例代码
const chunkSize = 2 * 1024 * 1024; // 2MB
const file = e.target.files[0];
const chunks = [];
let start = 0;

while (start < file.size) {
  const end = Math.min(start + chunkSize, file.size);
  const chunk = file.slice(start, end);
  chunks.push(chunk);
  start = end;
}
```

2. **计算文件唯一标识（hash）**
```typescript
// 使用SparkMD5计算文件hash
import SparkMD5 from 'spark-md5';

async function calculateHash(file) {
  return new Promise((resolve) => {
    const spark = new SparkMD5.ArrayBuffer();
    const reader = new FileReader();
    const chunks = [];
    let currentChunk = 0;
    const chunkSize = 2 * 1024 * 1024;
    
    function loadNext() {
      const start = currentChunk * chunkSize;
      const end = Math.min(start + chunkSize, file.size);
      reader.readAsArrayBuffer(file.slice(start, end));
    }
    
    reader.onload = (e) => {
      spark.append(e.target.result);
      currentChunk++;
      
      if (currentChunk < Math.ceil(file.size / chunkSize)) {
        loadNext();
      } else {
        resolve(spark.end());
      }
    };
    
    loadNext();
  });
}
```

3. **上传前验证（秒传）**
```typescript
// 验证文件是否已存在
async function verifyUpload(fileHash, fileName) {
  const { data } = await axios.post('/api/upload/verify', {
    fileHash,
    fileName
  });
  return data;
}
```

4. **并行上传分片**
```typescript
// 上传分片
async function uploadChunks(chunks, fileHash, fileName, uploadedList = []) {
  const requests = chunks
    .filter((_, index) => !uploadedList.includes(index)) // 过滤已上传的分片
    .map((chunk, index) => {
      const formData = new FormData();
      formData.append('chunk', chunk);
      formData.append('hash', fileHash);
      formData.append('filename', fileName);
      formData.append('chunkIndex', index);
      
      return axios.post('/api/upload/chunk', formData, {
        onUploadProgress: (e) => {
          // 更新上传进度
        }
      });
    });
    
  return Promise.all(requests);
}
```

5. **请求合并分片**
```typescript
// 合并请求
async function mergeRequest(fileHash, fileName, size) {
  const { data } = await axios.post('/api/upload/merge', {
    fileHash,
    fileName,
    size
  });
  return data;
}
```

### 完整上传过程

```typescript
async function handleUpload() {
  const fileHash = await calculateHash(file);
  const { uploaded, uploadedList } = await verifyUpload(fileHash, file.name);
  
  if (uploaded) {
    // 文件已存在，秒传成功
    return;
  }
  
  // 分片上传
  const chunks = createFileChunks(file);
  await uploadChunks(chunks, fileHash, file.name, uploadedList);
  
  // 请求合并
  await mergeRequest(fileHash, file.name, file.size);
}
```

## 后端实现（mall-server）

### 技术选型
- 使用 `Node.js` 或 `Java` 作为后端语言
- 使用 `multer`（Node.js）或 `commons-fileupload`（Java）处理文件上传
- 使用 `fs-extra`（Node.js）或 `File API`（Java）进行文件操作

### 实现步骤（以Node.js为例）

1. **验证接口**
```javascript
// 验证文件是否已存在
router.post('/verify', async (req, res) => {
  const { fileHash, fileName } = req.body;
  const filePath = path.resolve(UPLOAD_DIR, fileHash); // UPLOAD_DIR为上传目录
  
  // 验证文件是否已存在
  if (fs.existsSync(filePath)) {
    return res.json({
      success: true,
      uploaded: true
    });
  }
  
  // 获取已上传的分片列表
  const uploadedList = await getUploadedChunks(fileHash);
  
  res.json({
    success: true,
    uploaded: false,
    uploadedList
  });
});

// 获取已上传的分片
async function getUploadedChunks(fileHash) {
  const chunksDir = path.resolve(UPLOAD_DIR, 'chunks', fileHash);
  if (!fs.existsSync(chunksDir)) {
    return [];
  }
  
  const files = await fs.readdir(chunksDir);
  return files.map(file => parseInt(file.split('-')[1]));
}
```

2. **分片上传接口**
```javascript
// 上传分片
router.post('/chunk', upload.single('chunk'), async (req, res) => {
  const { hash: fileHash, filename, chunkIndex } = req.body;
  const chunksDir = path.resolve(UPLOAD_DIR, 'chunks', fileHash);
  
  // 创建分片目录
  if (!fs.existsSync(chunksDir)) {
    await fs.mkdir(chunksDir, { recursive: true });
  }
  
  // 分片文件路径
  const chunkPath = path.resolve(chunksDir, `chunk-${chunkIndex}`);
  
  // 保存分片
  await fs.rename(req.file.path, chunkPath);
  
  res.json({
    success: true,
    message: '分片上传成功'
  });
});
```

3. **合并分片接口**
```javascript
// 合并分片
router.post('/merge', async (req, res) => {
  const { fileHash, fileName, size } = req.body;
  const chunksDir = path.resolve(UPLOAD_DIR, 'chunks', fileHash);
  const filePath = path.resolve(UPLOAD_DIR, fileHash);
  
  // 获取所有分片
  const chunks = await fs.readdir(chunksDir);
  
  // 按照索引排序
  chunks.sort((a, b) => {
    return parseInt(a.split('-')[1]) - parseInt(b.split('-')[1]);
  });
  
  // 合并分片
  await mergeChunks(chunks, chunksDir, filePath);
  
  // 保存文件信息到数据库
  // ...
  
  res.json({
    success: true,
    url: `/uploads/${fileHash}`, // 文件路径
    message: '文件上传成功'
  });
});

// 合并分片的方法
async function mergeChunks(chunks, chunksDir, filePath) {
  // 创建写入流
  const writeStream = fs.createWriteStream(filePath);
  
  for (const chunk of chunks) {
    const chunkPath = path.resolve(chunksDir, chunk);
    // 创建读取流
    const readStream = fs.createReadStream(chunkPath);
    // 管道连接
    await new Promise((resolve) => {
      readStream.pipe(writeStream, { end: false });
      readStream.on('end', resolve);
    });
    // 删除分片
    await fs.unlink(chunkPath);
  }
  
  // 关闭写入流
  writeStream.end();
  
  // 删除分片目录
  await fs.rmdir(chunksDir);
}
```

## 关键注意事项

1. **分片大小选择**
   - 太小：请求数量增多，服务器压力大
   - 太大：单个请求时间长，失败风险高
   - 推荐：2MB ~ 5MB

2. **并发数控制**
   - 浏览器对同域名并发请求有限制（通常为6-8个）
   - 建议控制并发数在3-5个

3. **错误处理**
   - 实现分片上传失败后的重试机制
   - 给用户提供手动重试选项

4. **安全考虑**
   - 验证文件类型和大小
   - 限制上传速率和文件大小
   - 服务器端进行文件安全扫描

5. **性能优化**
   - 使用Web Worker计算文件hash，避免阻塞主线程
   - 分片上传采用并发控制
   - 服务端使用流式处理，减少内存占用

## 后续扩展

1. **上传进度可视化**：提供整体和分片级别的进度条
2. **拖拽上传**：支持拖拽文件到指定区域上传
3. **多文件上传**：同时处理多个文件的上传
4. **限速功能**：控制上传带宽
5. **预览功能**：上传完成后提供文件预览

---

以上方案可根据具体业务需求和项目特点进行调整和优化。 