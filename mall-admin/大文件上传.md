# 大文件上传实现方案

## 基本概念

大文件上传主要解决以下问题：
- 上传大文件时浏览器可能崩溃
- 上传过程中断后需要重新上传
- 服务器处理大文件时可能超时
- 网络波动导致上传失败

## 实现思路

### 核心技术点
1. **文件分片**：将大文件切分成固定大小的小块
2. **断点续传**：记录已上传的分片，支持中断后继续上传
3. **文件秒传**：通过文件hash验证，避免重复上传相同文件
4. **分片验证**：验证分片的完整性和正确性
5. **分片合并**：所有分片上传完成后，服务端合并为完整文件

## 简单版流程

```
前端                                    后端
  |                                      |
  |--- 选择文件 -----------------------> |
  |                                      |
  |--- 文件分片 -----------------------> |
  |                                      |
  |--- 上传分片1 ----------------------> |--- 保存分片1
  |                                      |
  |--- 上传分片2 ----------------------> |--- 保存分片2
  |                                      |
  |--- 上传分片N ----------------------> |--- 保存分片N
  |                                      |
  |--- 请求合并文件 -------------------> |--- 合并所有分片
  |                                      |
  |<-- 返回文件URL或存储路径 ----------- |
  |                                      |
```

## 完整版流程

```
前端                                    后端
  |                                      |
  |--- 选择文件 -----------------------> |
  |                                      |
  |--- 计算文件MD5/hash ---------------> |
  |                                      |
  |--- 发送文件hash验证请求 -----------> |--- 检查文件是否已存在
  |                                      |
  |<-- 返回验证结果和已上传分片信息 ---- |
  |    (如果文件已存在则秒传完成)        |
  |                                      |
  |--- 文件分片 -----------------------> |
  |                                      |
  |--- 并行上传分片1 ------------------> |--- 保存分片1
  |    (带有文件hash+分片索引)           |    (验证分片有效性)
  |                                      |
  |--- 并行上传分片2 ------------------> |--- 保存分片2
  |                                      |    (验证分片有效性)
  |                                      |
  |    ... (多个分片并行上传) ...        |
  |                                      |
  |--- 监控上传进度 --------------------> |
  |                                      |
  |--- 出错重试特定分片 ---------------> |
  |                                      |
  |--- 请求合并文件 -------------------> |--- 验证所有分片完整性
  |    (带有文件hash)                   |
  |                                      |--- 合并所有分片
  |                                      |
  |                                      |--- 删除临时分片
  |                                      |
  |<-- 返回文件URL和存储路径 ----------- |
  |                                      |
```

## 前端实现（mall-admin）

### 技术选型
- 使用 `SparkMD5` 库计算文件 hash
- 使用 `File API` 进行文件分片
- 使用 `axios` 进行请求发送和上传
- 使用 `Promise.all` 或 `async/await` 管理并发上传

### 实现步骤

1. **文件选择与分片**
```typescript
// 示例代码
const chunkSize = 2 * 1024 * 1024; // 2MB
const file = e.target.files[0];
const chunks = [];
let start = 0;

while (start < file.size) {
  const end = Math.min(start + chunkSize, file.size);
  const chunk = file.slice(start, end);
  chunks.push(chunk);
  start = end;
}
```

2. **计算文件唯一标识（hash）**
```typescript
// 使用SparkMD5计算文件hash
import SparkMD5 from 'spark-md5';

async function calculateHash(file) {
  return new Promise((resolve) => {
    const spark = new SparkMD5.ArrayBuffer();
    const reader = new FileReader();
    const chunks = [];
    let currentChunk = 0;
    const chunkSize = 2 * 1024 * 1024;
    
    function loadNext() {
      const start = currentChunk * chunkSize;
      const end = Math.min(start + chunkSize, file.size);
      reader.readAsArrayBuffer(file.slice(start, end));
    }
    
    reader.onload = (e) => {
      spark.append(e.target.result);
      currentChunk++;
      
      if (currentChunk < Math.ceil(file.size / chunkSize)) {
        loadNext();
      } else {
        resolve(spark.end());
      }
    };
    
    loadNext();
  });
}
```

3. **上传前验证（秒传）**
```typescript
// 验证文件是否已存在
async function verifyUpload(fileHash, fileName) {
  const { data } = await axios.post('/api/upload/verify', {
    fileHash,
    fileName
  });
  return data;
}
```

4. **并行上传分片**
```typescript
// 上传分片
async function uploadChunks(chunks, fileHash, fileName, uploadedList = []) {
  const requests = chunks
    .filter((_, index) => !uploadedList.includes(index)) // 过滤已上传的分片
    .map((chunk, index) => {
      const formData = new FormData();
      formData.append('chunk', chunk);
      formData.append('hash', fileHash);
      formData.append('filename', fileName);
      formData.append('chunkIndex', index);
      
      return axios.post('/api/upload/chunk', formData, {
        onUploadProgress: (e) => {
          // 更新上传进度
        }
      });
    });
    
  return Promise.all(requests);
}
```

5. **请求合并分片**
```typescript
// 合并请求
async function mergeRequest(fileHash, fileName, size) {
  const { data } = await axios.post('/api/upload/merge', {
    fileHash,
    fileName,
    size
  });
  return data;
}
```

### 完整上传过程

```typescript
async function handleUpload() {
  const fileHash = await calculateHash(file);
  const { uploaded, uploadedList } = await verifyUpload(fileHash, file.name);
  
  if (uploaded) {
    // 文件已存在，秒传成功
    return;
  }
  
  // 分片上传
  const chunks = createFileChunks(file);
  await uploadChunks(chunks, fileHash, file.name, uploadedList);
  
  // 请求合并
  await mergeRequest(fileHash, file.name, file.size);
}
```

## 后端实现（mall-server）

### 技术选型
- 使用 `Node.js` 或 `Java` 作为后端语言
- 使用 `multer`（Node.js）或 `commons-fileupload`（Java）处理文件上传
- 使用 `fs-extra`（Node.js）或 `File API`（Java）进行文件操作

### 实现步骤（以Node.js为例）

1. **验证接口**
```javascript
// 验证文件是否已存在
router.post('/verify', async (req, res) => {
  const { fileHash, fileName } = req.body;
  const filePath = path.resolve(UPLOAD_DIR, fileHash); // UPLOAD_DIR为上传目录
  
  // 验证文件是否已存在
  if (fs.existsSync(filePath)) {
    return res.json({
      success: true,
      uploaded: true
    });
  }
  
  // 获取已上传的分片列表
  const uploadedList = await getUploadedChunks(fileHash);
  
  res.json({
    success: true,
    uploaded: false,
    uploadedList
  });
});

// 获取已上传的分片
async function getUploadedChunks(fileHash) {
  const chunksDir = path.resolve(UPLOAD_DIR, 'chunks', fileHash);
  if (!fs.existsSync(chunksDir)) {
    return [];
  }
  
  const files = await fs.readdir(chunksDir);
  return files.map(file => parseInt(file.split('-')[1]));
}
```

2. **分片上传接口**
```javascript
// 上传分片
router.post('/chunk', upload.single('chunk'), async (req, res) => {
  const { hash: fileHash, filename, chunkIndex } = req.body;
  const chunksDir = path.resolve(UPLOAD_DIR, 'chunks', fileHash);
  
  // 创建分片目录
  if (!fs.existsSync(chunksDir)) {
    await fs.mkdir(chunksDir, { recursive: true });
  }
  
  // 分片文件路径
  const chunkPath = path.resolve(chunksDir, `chunk-${chunkIndex}`);
  
  // 保存分片
  await fs.rename(req.file.path, chunkPath);
  
  res.json({
    success: true,
    message: '分片上传成功'
  });
});
```

3. **合并分片接口**
```javascript
// 合并分片
router.post('/merge', async (req, res) => {
  const { fileHash, fileName, size } = req.body;
  const chunksDir = path.resolve(UPLOAD_DIR, 'chunks', fileHash);
  const filePath = path.resolve(UPLOAD_DIR, fileHash);
  
  // 获取所有分片
  const chunks = await fs.readdir(chunksDir);
  
  // 按照索引排序
  chunks.sort((a, b) => {
    return parseInt(a.split('-')[1]) - parseInt(b.split('-')[1]);
  });
  
  // 合并分片
  await mergeChunks(chunks, chunksDir, filePath);
  
  // 保存文件信息到数据库
  // ...
  
  res.json({
    success: true,
    url: `/uploads/${fileHash}`, // 文件路径
    message: '文件上传成功'
  });
});

// 合并分片的方法
async function mergeChunks(chunks, chunksDir, filePath) {
  // 创建写入流
  const writeStream = fs.createWriteStream(filePath);
  
  for (const chunk of chunks) {
    const chunkPath = path.resolve(chunksDir, chunk);
    // 创建读取流
    const readStream = fs.createReadStream(chunkPath);
    // 管道连接
    await new Promise((resolve) => {
      readStream.pipe(writeStream, { end: false });
      readStream.on('end', resolve);
    });
    // 删除分片
    await fs.unlink(chunkPath);
  }
  
  // 关闭写入流
  writeStream.end();
  
  // 删除分片目录
  await fs.rmdir(chunksDir);
}
```

## 关键注意事项

1. **分片大小选择**
   - 太小：请求数量增多，服务器压力大
   - 太大：单个请求时间长，失败风险高
   - 推荐：2MB ~ 5MB

2. **并发数控制**
   - 浏览器对同域名并发请求有限制（通常为6-8个）
   - 建议控制并发数在3-5个

3. **错误处理**
   - 实现分片上传失败后的重试机制
   - 给用户提供手动重试选项

4. **安全考虑**
   - 验证文件类型和大小
   - 限制上传速率和文件大小
   - 服务器端进行文件安全扫描

5. **性能优化**
   - 使用Web Worker计算文件hash，避免阻塞主线程
   - 分片上传采用并发控制
   - 服务端使用流式处理，减少内存占用

## 后续扩展

1. **上传进度可视化**：提供整体和分片级别的进度条
2. **拖拽上传**：支持拖拽文件到指定区域上传
3. **多文件上传**：同时处理多个文件的上传
4. **限速功能**：控制上传带宽
5. **预览功能**：上传完成后提供文件预览

---

以上方案可根据具体业务需求和项目特点进行调整和优化。 

## 断点续传详细实现

### 什么是断点续传？

断点续传是指在文件上传过程中，如果因为网络问题、浏览器崩溃或用户主动暂停等原因导致上传中断，可以从中断的位置继续上传，而不必重新上传整个文件的技术。

### 为什么需要断点续传？

1. **节省时间和网络资源**：避免因中断而重新上传整个文件
2. **提升用户体验**：特别是大文件上传时，中断后不必从头开始
3. **应对网络不稳定场景**：在网络波动频繁的环境下更为实用

### 断点续传的基本原理

断点续传的核心原理很简单：**将大文件分割成多个小块，分别上传，并记录已上传的部分，中断后只上传未完成的部分**。

### 实现断点续传的详细步骤

#### 前端部分：

1. **文件分片**：
   ```javascript
   // 分片大小通常为 2MB~5MB
   const chunkSize = 2 * 1024 * 1024; // 2MB
   const file = input.files[0];
   const chunks = [];
   
   // 切割文件
   let start = 0;
   while (start < file.size) {
     const end = Math.min(start + chunkSize, file.size);
     const chunk = file.slice(start, end);
     chunks.push(chunk);
     start = end;
   }
   ```

2. **生成文件标识**：
   - 使用文件名、大小等信息作为标识
   - 更可靠的方法是计算文件的哈希值（如MD5），但计算大文件哈希可能耗时较长

3. **上传前检查**：
   - 向服务器发送文件标识，查询已上传的分片
   - 接收服务器返回的已上传分片列表
   ```javascript
   // 检查已上传的分片
   const checkExistingChunks = async (fileName, totalChunks) => {
     const response = await axios.post('/api/upload/verify', {
       filename: fileName,
       totalChunks
     });
     
     if (response.data.code === 200) {
       return response.data.data.uploadedChunks || [];
     }
     return [];
   };
   ```

4. **上传分片**：
   - 跳过已上传的分片，只上传未上传的部分
   - 可以顺序上传，也可以并发上传多个分片
   ```javascript
   // 上传单个分片
   const uploadChunk = async (chunk, index, fileName) => {
     const formData = new FormData();
     formData.append('chunk', chunk);
     formData.append('index', index);
     formData.append('filename', fileName);
     formData.append('totalChunks', chunks.length);
     
     const response = await axios.post('/api/upload/chunk', formData);
     return response.data.code === 200;
   };
   
   // 上传所有分片（跳过已上传的）
   const uploadChunks = async (chunks, fileName, existingChunks = []) => {
     for (let i = 0; i < chunks.length; i++) {
       // 跳过已上传的分片
       if (existingChunks.includes(i)) {
         console.log(`分片 ${i} 已上传，跳过`);
         continue;
       }
       
       await uploadChunk(chunks[i], i, fileName);
     }
   };
   ```

5. **合并请求**：
   - 所有分片上传完成后，发送合并请求
   ```javascript
   // 请求合并文件
   const mergeFile = async (fileName, totalChunks) => {
     const response = await axios.post('/api/upload/merge', {
       filename: fileName,
       totalChunks
     });
     return response.data;
   };
   ```

6. **上传状态管理**：
   - 记录上传进度
   - 实现暂停/继续功能
   - 处理刷新页面后的恢复上传

#### 后端部分：

1. **分片接收与存储**：
   ```javascript
   // 接收分片
   app.post('/api/upload/chunk', upload.single('chunk'), (req, res) => {
     const { index, filename, totalChunks } = req.body;
     
     // 验证参数
     if (!index || !filename || !totalChunks) {
       return res.status(400).json({ error: '参数不完整' });
     }
     
     // 存储分片
     const chunkDir = path.join(uploadDir, `chunks/${filename}`);
     if (!fs.existsSync(chunkDir)) {
       fs.mkdirSync(chunkDir, { recursive: true });
     }
     
     // 将分片保存到以索引命名的文件
     const chunkPath = path.join(chunkDir, index.toString());
     fs.renameSync(req.file.path, chunkPath);
     
     res.json({ code: 200, message: '分片上传成功' });
   });
   ```

2. **查询已上传分片**：
   ```javascript
   // 验证已上传分片
   app.post('/api/upload/verify', (req, res) => {
     const { filename, totalChunks } = req.body;
     
     if (!filename || !totalChunks) {
       return res.status(400).json({ error: '参数不完整' });
     }
     
     const chunkDir = path.join(uploadDir, `chunks/${filename}`);
     const uploadedChunks = [];
     
     // 检查分片目录是否存在
     if (fs.existsSync(chunkDir)) {
       const files = fs.readdirSync(chunkDir);
       
       // 检查每个分片的状态
       for (let i = 0; i < parseInt(totalChunks); i++) {
         if (files.includes(i.toString())) {
           uploadedChunks.push(i);
         }
       }
     }
     
     res.json({
       code: 200,
       data: { uploadedChunks }
     });
   });
   ```

3. **合并分片**：
   ```javascript
   // 合并分片
   app.post('/api/upload/merge', (req, res) => {
     const { filename, totalChunks } = req.body;
     
     if (!filename || !totalChunks) {
       return res.status(400).json({ error: '参数不完整' });
     }
     
     const chunkDir = path.join(uploadDir, `chunks/${filename}`);
     
     // 检查分片是否全部上传完成
     const files = fs.readdirSync(chunkDir);
     const validFiles = files.filter(file => {
       const index = parseInt(file);
       return !isNaN(index) && index >= 0 && index < parseInt(totalChunks);
     });
     
     if (validFiles.length !== parseInt(totalChunks)) {
       return res.json({
         code: 400,
         message: `分片不完整，已上传 ${validFiles.length}/${totalChunks}`
       });
     }
     
     // 生成最终文件名
     const fileExt = path.extname(filename);
     const finalName = `${Date.now()}-${filename}`;
     const filePath = path.join(uploadDir, finalName);
     
     // 创建写入流
     const writeStream = fs.createWriteStream(filePath);
     
     // 按顺序合并分片
     for (let i = 0; i < parseInt(totalChunks); i++) {
       const chunkPath = path.join(chunkDir, i.toString());
       const chunkData = fs.readFileSync(chunkPath);
       writeStream.write(chunkData);
       // 删除分片
       fs.unlinkSync(chunkPath);
     }
     
     // 关闭写入流
     writeStream.end();
     
     // 删除分片目录
     fs.rmdirSync(chunkDir, { recursive: true });
     
     res.json({
       code: 200,
       message: '文件合并成功',
       url: `/uploads/${finalName}`
     });
   });
   ```

### 断点续传的进阶优化

1. **分片传输的安全性**：
   - 添加用户验证，确保只有授权用户可以上传
   - 对分片添加签名，防止恶意上传

2. **分片上传的并发控制**：
   - 限制并发数量（通常3-5个），避免过多请求压垮服务器
   - 实现优先级队列，失败的分片优先重试

3. **断点续传的持久化**：
   - 使用localStorage或IndexedDB保存上传状态，在页面刷新后依然可以恢复
   - 在服务器端设置分片的过期时间，定期清理未完成的上传

4. **上传进度可视化**：
   - 实现整体进度条和分片级别的进度显示
   - 展示预计剩余时间和上传速度

5. **网络自适应**：
   - 根据网络状况动态调整并发数和分片大小
   - 在网络条件差的情况下，自动降低分片大小

### 常见问题及解决方案

1. **分片乱序问题**：
   - 确保分片按照索引顺序合并
   - 在前端记录每个分片的索引，在后端严格按照索引排序

2. **临时文件管理**：
   - 设置定时任务清理长时间未完成的上传
   - 对每个用户设置存储空间限制

3. **大文件哈希计算**：
   - 使用Web Worker在后台计算，避免阻塞主线程
   - 使用抽样计算或分片计算，提高速度

4. **不同浏览器兼容性**：
   - 针对不同浏览器的File API差异做兼容处理
   - 对旧版浏览器提供回退方案

### 断点续传流程总结

1. **前期准备**：
   - 生成文件标识（名称或MD5）
   - 将文件分割成多个小块
   
2. **上传前检查**：
   - 向服务器发送查询请求，获取已上传分片
   - 判断是否可以秒传（文件已存在）
   
3. **分片上传**：
   - 跳过已上传的分片，继续上传未完成的部分
   - 支持暂停/继续操作
   
4. **上传后处理**：
   - 所有分片上传完成后，请求服务器合并
   - 服务器合并分片，删除临时文件
   
5. **异常处理**：
   - 上传失败时自动重试
   - 网络中断后能够恢复上传

## 基于文件哈希的优化

当前的断点续传实现基于文件名作为唯一标识，这有一些局限性：

### 当前实现（基于文件名）的局限性

1. **不支持秒传**：无法识别完全相同但名称不同的文件
2. **唯一性不足**：不同文件可能具有相同的名称，导致混淆
3. **安全性较低**：无法验证文件内容的完整性和一致性

### 为什么需要添加哈希

添加文件哈希（如MD5）可以实现：

1. **文件秒传**：通过哈希值检查服务器是否已有相同文件，有则直接标记为上传成功
2. **内容唯一标识**：哈希值基于文件内容生成，提供更可靠的唯一标识
3. **完整性校验**：可以验证分片和最终文件的完整性，避免损坏

### 实现哈希的方法

要添加哈希支持，可以这样实现：

```javascript
// 前端计算文件哈希
import SparkMD5 from 'spark-md5';

async function calculateFileHash(file) {
  return new Promise(resolve => {
    const spark = new SparkMD5.ArrayBuffer();
    const reader = new FileReader();
    const chunkSize = 2 * 1024 * 1024;
    let currentChunk = 0;
    const chunks = Math.ceil(file.size / chunkSize);
    
    reader.onload = e => {
      spark.append(e.target!.result as ArrayBuffer);
      currentChunk++;
      
      if (currentChunk < chunks) {
        loadNext();
      } else {
        resolve(spark.end()); // 返回MD5哈希值
      }
    };
    
    reader.onerror = reject;

    function loadNext() {
      const start = currentChunk * chunkSize;
      const end = Math.min(start + chunkSize, file.size);
      reader.readAsArrayBuffer(file.slice(start, end));
    }
    
    loadNext();
  });
}
```

### 如何改进当前实现

如果要添加哈希支持，您可以：

1. 在前端添加文件哈希计算（使用Web Worker避免阻塞主线程）
2. 修改后端接口，支持基于哈希的文件验证
3. 实现文件秒传功能：如果服务器已有相同哈希的文件，直接返回成功

这是断点续传的进阶功能，可以在基础功能稳定后添加。 

## 基于MD5的断点续传与兼容方案

### 一、前端（md5Upload.vue）主要改动

1. **计算文件 MD5**  
   - 上传前，主线程用 SparkMD5 计算整个文件的 MD5，作为唯一标识。
2. **上传前验证**  
   - 请求 `/api/upload/verify`，参数带上 `fileHash`（MD5）和 `fileName`。
   - 后端返回已上传分片列表。
3. **分片上传**  
   - 每个分片上传时带上 `fileHash`、`fileName`、`chunkIndex`。
   - 只上传未上传的分片。
4. **合并请求**  
   - 合并时带上 `fileHash`、`fileName`、`size`。

---

### 二、后端兼容性设计

1. **接口参数兼容**  
   - `/api/upload/verify`、`/api/upload/chunk`、`/api/upload/merge` 支持 fileHash+fileName 或仅 fileName 两种模式。
   - 如果有 fileHash 优先用 fileHash 作为目录名和唯一标识，否则用 fileName（兼容老前端）。
2. **分片存储目录**  
   - 优先用 fileHash 作为分片目录名，没有 fileHash 时用 fileName。
3. **合并逻辑**  
   - 合并时也优先用 fileHash，没有则用 fileName。

---

### 三、具体实现步骤

#### 1. 前端：md5Upload.vue
- 引入 SparkMD5
- 计算 MD5
- 所有请求都带 fileHash
- 其余逻辑与 upload.vue 类似

#### 2. 后端 controller & routes
- 所有相关接口参数支持 fileHash（可选），优先 fileHash，没有则用 fileName
- 目录结构：`uploads/chunks/{fileHash or fileName}/`
- 合并后文件名建议用 hash+原始扩展名，避免重名

---

### 四、代码实现

#### 1. 前端（md5Upload.vue）主要片段

```typescript
import SparkMD5 from 'spark-md5';

async function calculateFileMD5(file: File): Promise<string> {
  return new Promise((resolve, reject) => {
    const chunkSize = 2 * 1024 * 1024;
    const chunks = Math.ceil(file.size / chunkSize);
    let currentChunk = 0;
    const spark = new SparkMD5.ArrayBuffer();
    const reader = new FileReader();

    reader.onload = (e) => {
      spark.append(e.target!.result as ArrayBuffer);
      currentChunk++;
      if (currentChunk < chunks) {
        loadNext();
      } else {
        resolve(spark.end());
      }
    };
    reader.onerror = reject;

    function loadNext() {
      const start = currentChunk * chunkSize;
      const end = Math.min(start + chunkSize, file.size);
      reader.readAsArrayBuffer(file.slice(start, end));
    }
    loadNext();
  });
}

// 上传前
const fileHash = await calculateFileMD5(file.value!);

// 验证接口
const verifyRes = await request.post('/upload/verify', {
  fileHash,
  fileName: file.value!.name,
  totalChunks: totalChunks.value
});

// 上传分片接口
formData.append('fileHash', fileHash);
// 合并接口同理
```

#### 2. 后端（伪代码/关键片段）

```js
// 获取唯一标识
const getFileKey = (req) => req.body.fileHash || req.body.filename;

// verify
const chunkDir = path.join(__dirname, '../../public/uploads/chunks', getFileKey(req));

// chunk
const chunkDir = path.join(__dirname, '../../public/uploads/chunks', getFileKey(req));

// merge
const chunkDir = path.join(__dirname, '../../public/uploads/chunks', getFileKey(req));
const finalFileName = req.body.fileHash
  ? `${req.body.fileHash}${path.extname(req.body.fileName)}`
  : req.body.fileName;
```

---

### 五、兼容性说明

- 老前端（只传 fileName）依然可用，后端自动 fallback 到 fileName 模式。
- 新前端（md5Upload.vue）优先用 fileHash，支持秒传、内容唯一性更好。

---

这样即可实现基于MD5的断点续传，并兼容原有的上传方式。 

## 基于MD5的断点续传实现详解

### 一、实现概述

基于MD5的断点续传在原有功能基础上增加了以下核心特性：

1. **文件秒传**：相同内容的文件无需重复上传
2. **更可靠的唯一标识**：使用内容哈希而非文件名，防止同名不同内容的混淆
3. **文件完整性校验**：通过哈希值验证文件的完整性和一致性

### 二、技术实现细节

#### 1. 前端实现（md5Upload.vue）

##### 1.1 引入SparkMD5库

```bash
npm install spark-md5 --save
```

```typescript
import SparkMD5 from 'spark-md5';
```

##### 1.2 文件哈希计算

```typescript
// 计算文件的MD5哈希值
const calculateFileHash = (file: File): Promise<string> => {
  return new Promise((resolve, reject) => {
    const chunks = Math.ceil(file.size / chunkSize);
    const spark = new SparkMD5.ArrayBuffer();
    const fileReader = new FileReader();

    let currentChunk = 0;
    isCalculatingHash.value = true;
    hashPercent.value = 0;

    const loadNext = () => {
      const start = currentChunk * chunkSize;
      const end = Math.min(start + chunkSize, file.size);
      fileReader.readAsArrayBuffer(file.slice(start, end));
    };

    fileReader.onload = (e) => {
      if (e.target?.result) {
        spark.append(e.target.result as ArrayBuffer);
        currentChunk++;
        hashPercent.value = Math.floor((currentChunk / chunks) * 100);

        if (currentChunk < chunks) {
          loadNext();
        } else {
          const hash = spark.end();
          isCalculatingHash.value = false;
          console.log('文件MD5计算完成:', hash);
          resolve(hash);
        }
      }
    };

    fileReader.onerror = (error) => {
      isCalculatingHash.value = false;
      console.error('文件MD5计算失败:', error);
      reject(error);
    };

    loadNext();
  });
};
```

##### 1.3 文件选择时计算哈希

```typescript
// 处理文件选择（修改以添加MD5计算）
const handleFileChange = async (e: Event) => {
  const target = e.target as HTMLInputElement;
  if (target.files && target.files.length > 0) {
    file.value = target.files[0];
    calculateTotalChunks();

    // 计算文件MD5
    try {
      ElMessage.info('正在计算文件特征值，请稍候...');
      fileHash.value = await calculateFileHash(file.value);
      ElMessage.success('文件特征值计算完成');
    } catch (error) {
      console.error('计算文件特征值失败:', error);
      ElMessage.error('计算文件特征值失败，将使用文件名作为标识');
      fileHash.value = '';
    }
  }
};
```

##### 1.4 验证已上传分片（支持秒传）

```typescript
// 修改检查已上传的分片，添加fileHash参数
const checkExistingChunks = async (fileName: string, totalChunks: number) => {
  try {
    const requestData: Record<string, any> = {
      filename: fileName,
      totalChunks
    };

    // 添加文件哈希值（如果有）
    if (fileHash.value) {
      requestData.fileHash = fileHash.value;
    }

    const response = await request.post<ApiResponse>('/upload/verify', requestData);

    // 检查是否可以秒传
    if (response.code === 200 && response.data && response.data.uploaded === true) {
      // 文件已存在，可以秒传
      fileUrl.value = response.data.url;
      uploadSuccess.value = true;
      uploading.value = false;
      uploadProgress.value = 100;

      ElMessage.success('文件秒传成功！');
      return 'INSTANT_UPLOAD'; // 特殊标记，表示可以秒传
    }

    if (response.code === 200 && response.data && response.data.uploadedChunks) {
      return response.data.uploadedChunks;
    }

    return [];
  } catch (error) {
    console.error('检查已上传分片失败:', error);
    return [];
  }
};
```

##### 1.5 上传分片（带上哈希值）

```typescript
// 修改上传单个分片，添加fileHash参数
const uploadChunk = async (chunk: Blob, index: number, fileName: string) => {
  const formData = new FormData();
  formData.append('chunk', chunk, `${fileName}.part${index}`);
  formData.append('index', index.toString());
  formData.append('filename', fileName);
  formData.append('totalChunks', totalChunks.value.toString());

  // 添加文件哈希值（如果有）
  if (fileHash.value) {
    formData.append('fileHash', fileHash.value);
  }

  // 发送请求...
};
```

##### 1.6 合并文件（带上哈希值）

```typescript
// 修改合并文件的公共方法，添加fileHash参数
const mergeFile = async (fileName: string) => {
  try {
    // 请求合并文件
    const requestData: Record<string, any> = {
      filename: fileName,
      totalChunks: totalChunks.value
    };

    // 添加文件哈希值（如果有）
    if (fileHash.value) {
      requestData.fileHash = fileHash.value;
    }

    const response = await request.post<ApiResponse>('/upload/merge', requestData);

    // 处理响应...
  } catch (error) {
    // 错误处理...
  }
};
```

#### 2. 后端实现（uploadController.js）

##### 2.1 文件标识获取函数

```javascript
/**
 * 获取文件唯一标识，优先使用fileHash，如果没有则使用filename
 * 以保持向后兼容性
 * @param {Object} req - 请求对象
 * @returns {string} - 文件唯一标识
 */
const getFileKey = (req) => {
  return req.body.fileHash || req.body.filename;
};

/**
 * 获取最终文件名，使用fileHash+扩展名或自动生成唯一名称
 * @param {Object} req - 请求对象 
 * @returns {string} - 最终文件名
 */
const getFinalFileName = (req) => {
  const fileExt = path.extname(req.body.filename);

  if (req.body.fileHash) {
    // 如果有文件哈希，直接使用哈希作为文件名
    return `${req.body.fileHash}${fileExt}`;
  } else {
    // 否则使用时间戳+UUID生成唯一文件名
    return `${Date.now()}-${uuidv4()}${fileExt}`;
  }
};
```

##### 2.2 验证上传（支持秒传）

```javascript
exports.verifyUpload = catchAsync(async (req, res) => {
  const { filename, totalChunks, fileHash } = req.body;

  if (!filename || !totalChunks) {
    throw new ValidationError('参数不完整');
  }

  // 获取文件唯一标识（fileHash或filename）
  const fileKey = getFileKey(req);

  // 如果有fileHash，先检查是否可以秒传（完整文件是否已存在）
  if (fileHash) {
    const fileExt = path.extname(filename);
    const finalFilePath = path.join(__dirname, `../../public/uploads/${fileHash}${fileExt}`);

    if (fs.existsSync(finalFilePath)) {
      // 文件已存在，可以秒传
      const baseUrl = getBaseUrl(req);
      const fileUrl = `${baseUrl}/uploads/${fileHash}${fileExt}`;

      return res.status(200).json({
        code: 200,
        success: true,
        message: '文件已存在，可以秒传',
        data: {
          uploaded: true,
          url: fileUrl
        }
      });
    }
  }

  // 检查分片目录是否存在
  const chunkDir = path.join(__dirname, `../../public/uploads/chunks/${fileKey}`);
  const uploadedChunks = [];

  // 如果目录存在，检查已上传的分片
  if (fs.existsSync(chunkDir)) {
    // 读取目录中的所有文件并确定已上传的分片
    // ...
  }

  res.status(200).json({
    code: 200,
    success: true,
    message: '验证成功',
    data: {
      uploaded: false,
      uploadedChunks
    }
  });
});
```

##### 2.3 处理分片上传

```javascript
exports.uploadChunk = catchAsync(async (req, res) => {
  if (!req.file) {
    throw new ValidationError('没有接收到分片文件');
  }

  // 获取参数
  const { index, filename, totalChunks, fileHash } = req.body;
  
  // 获取文件唯一标识（fileHash或filename）
  const fileKey = getFileKey(req);

  // 创建临时目录，用于存储分片
  const chunkDir = path.join(__dirname, `../../public/uploads/chunks/${fileKey}`);
  if (!fs.existsSync(chunkDir)) {
    fs.mkdirSync(chunkDir, { recursive: true });
  }

  // 移动分片到目标目录，确保使用索引作为文件名
  const chunkPath = path.join(chunkDir, `${chunkIndex}`);
  fs.renameSync(req.file.path, chunkPath);

  // 返回响应...
});
```

##### 2.4 合并文件

```javascript
exports.mergeChunks = catchAsync(async (req, res) => {
  const { filename, totalChunks, fileHash } = req.body;

  // 获取文件唯一标识（fileHash或filename）
  const fileKey = getFileKey(req);

  const chunkDir = path.join(__dirname, `../../public/uploads/chunks/${fileKey}`);
  if (!fs.existsSync(chunkDir)) {
    throw new ValidationError('没有找到分片文件');
  }

  // 检查所有分片是否都已上传
  // ...

  // 生成最终文件名
  const uniqueFileName = fileHash ?
    `${fileHash}${path.extname(filename)}` :
    `${Date.now()}-${uuidv4()}${path.extname(filename)}`;

  const filePath = path.join(__dirname, `../../public/uploads/${uniqueFileName}`);

  // 合并分片...

  // 生成文件URL
  const baseUrl = getBaseUrl(req);
  const fileUrl = `${baseUrl}/uploads/${uniqueFileName}`;

  // 返回响应...
});
```

### 三、技术挑战与解决方案

#### 1. MD5计算性能

**挑战**：大文件计算MD5会阻塞主线程，导致UI卡顿。

**解决方案**：
- 使用分块计算策略，每次处理一小块文件
- 添加进度显示，提升用户体验
- 较复杂项目可使用Web Worker（本实现未使用，保持简单）

#### 2. 兼容性处理

**挑战**：需要保持旧版上传组件的功能正常运行。

**解决方案**：
- 后端使用`getFileKey`函数，优先使用fileHash，没有则回退到filename
- 确保所有API参数都向后兼容
- 新组件（md5Upload.vue）中添加相关逻辑，但不强制修改旧组件

#### 3. 秒传实现

**挑战**：如何快速确认服务器已有相同文件，避免重复上传。

**解决方案**：
- 在verify阶段检查完整文件是否已存在
- 如果存在则直接返回文件URL，跳过上传过程
- 前端添加逻辑识别秒传状态并更新UI

### 四、用户体验优化

1. **哈希计算进度显示**：
   - 添加进度条显示哈希计算进度
   - 提示用户当前正在进行哈希计算

2. **哈希计算完成提示**：
   - 计算完成后显示哈希值
   - 计算失败时提供友好错误提示

3. **秒传体验**：
   - 秒传成功时显示明确提示
   - 避免用户等待已存在文件的上传

### 五、后续扩展方向

1. **Web Worker支持**：
   - 将MD5计算迁移到Web Worker中执行
   - 避免主线程阻塞，提升大文件处理性能

2. **抽样计算**：
   - 对超大文件采用抽样计算哈希值
   - 牺牲少量准确性换取性能提升

3. **服务端集群优化**：
   - 在分布式存储系统中利用哈希实现文件去重
   - 基于哈希构建更高效的文件查找机制

4. **增强安全性**：
   - 使用哈希+用户ID防止跨用户访问文件
   - 添加文件访问权限控制

### 六、总结

基于MD5的断点续传在原有功能基础上提供了更强大的功能和更好的用户体验：

1. 通过内容哈希提供更可靠的文件唯一标识
2. 支持相同内容文件的秒传功能
3. 提供文件完整性校验能力
4. 保持与现有系统的兼容性

这一实现既满足了产品对大文件上传、断点续传和秒传的需求，又保持了代码的可维护性和兼容性，为未来功能扩展提供了良好基础。 

## 使用Web Worker优化MD5计算

在前面的章节中，我们讨论了计算文件MD5特征值的重要性以及性能挑战。对于大文件，在主线程计算MD5会导致界面卡顿，严重影响用户体验。本章节将详细介绍如何使用Web Worker技术在后台线程计算MD5，从而解决这一问题。

### 1. Web Worker基本原理

Web Worker允许在浏览器主线程之外创建独立的JavaScript线程，实现并行计算而不阻塞UI渲染。对于计算密集型任务（如MD5计算），这是理想的解决方案。

**主要优势：**

- **不阻塞UI**：计算在单独线程进行，主线程保持响应
- **性能提升**：可利用多核CPU并行处理
- **响应式体验**：用户可以继续与页面交互，无感知等待

### 2. 实现步骤

#### 2.1 创建Worker脚本文件

首先，在项目的`public`目录中创建一个专门用于MD5计算的Worker脚本文件：

```javascript
// public/md5Worker.js
// 导入SparkMD5库
self.importScripts('./spark-md5.min.js'); 

// 监听主线程消息
self.onmessage = function(e) {
  const { file, chunkSize } = e.data;
  calculateMD5(file, chunkSize);
};

/**
 * 在Worker中计算文件MD5哈希值
 * @param {File} file - 文件对象
 * @param {number} chunkSize - 分块大小
 */
function calculateMD5(file, chunkSize) {
  const chunks = Math.ceil(file.size / chunkSize);
  const spark = new self.SparkMD5.ArrayBuffer();
  let currentChunk = 0;
  
  // 使用FileReader读取文件块
  const fileReader = new FileReader();
  
  fileReader.onload = function(e) {
    // 将读取的块添加到哈希计算中
    spark.append(e.target.result);
    currentChunk++;
    
    // 报告进度给主线程
    self.postMessage({
      type: 'progress',
      data: {
        percent: Math.floor((currentChunk / chunks) * 100)
      }
    });
    
    if (currentChunk < chunks) {
      // 继续读取下一块
      loadNext();
    } else {
      // 计算完成，返回结果
      const hash = spark.end();
      self.postMessage({
        type: 'complete',
        data: { hash }
      });
    }
  };
  
  fileReader.onerror = function(error) {
    // 报告错误给主线程
    self.postMessage({
      type: 'error',
      data: { error: error.toString() }
    });
  };
  
  function loadNext() {
    const start = currentChunk * chunkSize;
    const end = Math.min(start + chunkSize, file.size);
    const chunk = file.slice(start, end);
    fileReader.readAsArrayBuffer(chunk);
  }
  
  // 开始加载第一个块
  loadNext();
}
```

#### 2.2 确保SparkMD5库可用

Worker需要访问SparkMD5库，需要确保它在public目录中：

```bash
# 安装SparkMD5库
npm install spark-md5 --save

# 复制库文件到public目录
cp node_modules/spark-md5/spark-md5.min.js public/
```

#### 2.3 修改Vue组件使用Worker

修改上传组件中的哈希计算逻辑：

```typescript
// webWorkerUpload.vue
import { ref, onMounted, computed, onUnmounted } from 'vue';
// 其他导入...

// 添加Worker引用
const worker = ref<Worker | null>(null);

/**
 * 使用Web Worker计算文件的MD5哈希值
 */
const calculateFileHash = (file: File): Promise<string> => {
  return new Promise((resolve, reject) => {
    // 终止已有的Worker
    if (worker.value) {
      worker.value.terminate();
    }
    
    try {
      // 创建新的Worker
      worker.value = new Worker('/md5Worker.js');
      
      // 设置计算状态
      isCalculatingHash.value = true;
      hashPercent.value = 0;
      
      // 处理Worker消息
      worker.value.onmessage = (e) => {
        const { type, data } = e.data;
        
        switch (type) {
          case 'progress':
            // 更新进度
            hashPercent.value = data.percent;
            break;
          case 'complete':
            // 计算完成
            isCalculatingHash.value = false;
            console.log('文件MD5计算完成(Worker):', data.hash);
            
            // 清理Worker
            if (worker.value) {
              worker.value.terminate();
              worker.value = null;
            }
            
            resolve(data.hash);
            break;
          case 'error':
            // 处理错误
            isCalculatingHash.value = false;
            console.error('文件MD5计算失败(Worker):', data.error);
            
            // 清理Worker
            if (worker.value) {
              worker.value.terminate();
              worker.value = null;
            }
            
            reject(new Error(data.error));
            break;
        }
      };
      
      // 处理Worker错误
      worker.value.onerror = (error) => {
        isCalculatingHash.value = false;
        console.error('Worker错误:', error);
        
        // 清理Worker
        if (worker.value) {
          worker.value.terminate();
          worker.value = null;
        }
        
        // 当Worker失败时，尝试回退到主线程计算
        ElMessage.warning('后台计算失败，将在主线程计算，UI可能暂时卡顿');
        calculateFileHashInMainThread(file)
          .then(resolve)
          .catch(reject);
      };
      
      // 发送文件和参数给Worker
      worker.value.postMessage({
        file,
        chunkSize
      });
    } catch (error) {
      // 如果Worker创建失败，回退到主线程计算
      console.error('创建Worker失败:', error);
      isCalculatingHash.value = true;
      hashPercent.value = 0;
      
      ElMessage.warning('Web Worker不可用，将在主线程计算，UI可能暂时卡顿');
      calculateFileHashInMainThread(file)
        .then(resolve)
        .catch(reject);
    }
  });
};

// 保留主线程计算方法作为备用
const calculateFileHashInMainThread = (file: File): Promise<string> => {
  // 主线程计算逻辑（与原来的calculateFileHash相同）
  // ...
};

// 组件卸载时清理Worker
onUnmounted(() => {
  // 其他清理...
  if (worker.value) {
    worker.value.terminate();
    worker.value = null;
  }
});
```

### 3. 性能对比与优化效果

使用Web Worker计算MD5与主线程计算相比有以下显著差异：

| 比较项 | 主线程计算 | Web Worker计算 |
|-------|----------|--------------|
| UI响应性 | 计算时界面卡顿 | 界面保持流畅响应 |
| CPU利用率 | 单线程，利用率低 | 可利用多核并行计算 |
| 计算速度 | 阻塞其他任务 | 在大文件上可能更快 |
| 用户体验 | 计算时无法操作界面 | 可继续交互，无感知等待 |
| 内存占用 | 在主线程占用内存 | 在独立线程占用内存 |

### 4. 注意事项与兼容性

1. **浏览器兼容性**：大多数现代浏览器支持Web Worker，但需要考虑老旧浏览器兼容
2. **传输限制**：
   - Worker与主线程之间通过消息传递通信，不共享内存
   - 大数据传输可能导致性能问题（复制开销）
3. **错误处理**：
   - 应始终实现回退机制，当Worker失败时回到主线程计算
   - 清理未使用的Worker避免内存泄漏
4. **调试复杂性**：Worker中的代码调试相对困难

### 5. 进一步优化思路

1. **Transferable Objects**：使用可转移对象减少数据复制开销
2. **Worker Pool**：创建Worker池管理多个并行任务
3. **分块策略优化**：根据设备性能动态调整分块大小
4. **混合计算**：小文件在主线程计算，大文件使用Worker
5. **缓存结果**：存储计算结果，避免重复计算

### 6. 总结

使用Web Worker计算文件MD5哈希值是大文件上传优化的关键步骤之一。通过将计算密集型任务移至后台线程，我们显著提升了用户体验，保持界面响应性，同时在多核设备上可能获得性能提升。

结合断点续传、文件分片和Web Worker优化，我们的大文件上传功能可以满足各种复杂业务场景的需求，为用户提供流畅、可靠的上传体验。 

## 为什么需要计算文件特征值而非使用随机值

在大文件上传系统中，我们使用文件的特征值（如MD5哈希）作为文件标识符，而不是简单地生成随机ID。这一设计决策有其深刻的技术原因：

### 1. 内容唯一性

- **特征值（MD5等）**：是基于文件内容本身计算得出的，只要文件内容相同，无论文件名是什么，计算出的特征值都是相同的。
- **随机值**：与文件内容完全无关，相同内容的文件每次生成的随机ID都不同。

### 2. 秒传功能的实现

秒传是大文件上传中的关键优化功能，它依赖于特征值：

- **使用特征值**：服务器可以根据特征值快速判断该文件是否已存在于存储系统中，如果存在则无需再次上传，直接返回成功。
- **使用随机值**：无法判断内容相同的文件是否已上传过，每次都必须重新上传整个文件。

### 3. 数据完整性验证

- **特征值**：可以作为文件内容的"数字指纹"，用于验证文件是否在传输过程中损坏或被篡改。
- **随机值**：不包含任何关于文件内容的信息，无法用于验证文件完整性。

### 4. 存储空间优化

- **特征值**：允许存储系统识别内容相同的文件，实现文件去重，减少存储空间占用。
- **随机值**：会导致相同内容的文件被重复存储多次。

### 5. 断点续传的可靠性

- **特征值**：如果用户重新选择同一文件上传，系统可以识别出这是同一文件，继续之前的上传进度。
- **随机值**：每次选择文件都会生成新的随机ID，导致之前已上传的分片无法被正确关联。

### 6. 分布式系统中的一致性

- **特征值**：在分布式存储系统中，基于内容的特征值可以确保不同节点对同一文件的识别是一致的。
- **随机值**：不同节点可能生成不同的随机ID，造成系统不一致。

### 性能考量

计算文件特征值（尤其是大文件）确实有一定的性能开销，但这一开销是值得的，因为它带来的好处远超过计算成本。为了优化性能，我们采用了以下策略：

1. **分块计算**：不一次性加载整个文件，而是分块读取并计算
2. **进度显示**：向用户展示计算进度，提升用户体验
3. **Web Worker**：可选择在后台线程中计算，避免阻塞主线程
4. **抽样计算**：对于超大文件，可以考虑只计算部分内容的特征值（有损精度，但大幅提升性能）

总结来说，虽然特征值的计算会增加一些前端计算负担，但它为整个上传系统带来的功能和优化价值是随机ID无法比拟的。 