# 大文件上传实现方案

## 基本概念

大文件上传主要解决以下问题：
- 上传大文件时浏览器可能崩溃
- 上传过程中断后需要重新上传
- 服务器处理大文件时可能超时
- 网络波动导致上传失败

## 实现思路

### 核心技术点
1. **文件分片**：将大文件切分成固定大小的小块
2. **断点续传**：记录已上传的分片，支持中断后继续上传
3. **文件秒传**：通过文件hash验证，避免重复上传相同文件
4. **分片验证**：验证分片的完整性和正确性
5. **分片合并**：所有分片上传完成后，服务端合并为完整文件

## 简单版流程

```
前端                                    后端
  |                                      |
  |--- 选择文件 -----------------------> |
  |                                      |
  |--- 文件分片 -----------------------> |
  |                                      |
  |--- 上传分片1 ----------------------> |--- 保存分片1
  |                                      |
  |--- 上传分片2 ----------------------> |--- 保存分片2
  |                                      |
  |--- 上传分片N ----------------------> |--- 保存分片N
  |                                      |
  |--- 请求合并文件 -------------------> |--- 合并所有分片
  |                                      |
  |<-- 返回文件URL或存储路径 ----------- |
  |                                      |
```

## 完整版流程

```
前端                                    后端
  |                                      |
  |--- 选择文件 -----------------------> |
  |                                      |
  |--- 计算文件MD5/hash ---------------> |
  |                                      |
  |--- 发送文件hash验证请求 -----------> |--- 检查文件是否已存在
  |                                      |
  |<-- 返回验证结果和已上传分片信息 ---- |
  |    (如果文件已存在则秒传完成)        |
  |                                      |
  |--- 文件分片 -----------------------> |
  |                                      |
  |--- 并行上传分片1 ------------------> |--- 保存分片1
  |    (带有文件hash+分片索引)           |    (验证分片有效性)
  |                                      |
  |--- 并行上传分片2 ------------------> |--- 保存分片2
  |                                      |    (验证分片有效性)
  |                                      |
  |    ... (多个分片并行上传) ...        |
  |                                      |
  |--- 监控上传进度 --------------------> |
  |                                      |
  |--- 出错重试特定分片 ---------------> |
  |                                      |
  |--- 请求合并文件 -------------------> |--- 验证所有分片完整性
  |    (带有文件hash)                   |
  |                                      |--- 合并所有分片
  |                                      |
  |                                      |--- 删除临时分片
  |                                      |
  |<-- 返回文件URL和存储路径 ----------- |
  |                                      |
```

## 前端实现（mall-admin）

### 技术选型
- 使用 `SparkMD5` 库计算文件 hash
- 使用 `File API` 进行文件分片
- 使用 `axios` 进行请求发送和上传
- 使用 `Promise.all` 或 `async/await` 管理并发上传

### 实现步骤

1. **文件选择与分片**
```typescript
// 示例代码
const chunkSize = 2 * 1024 * 1024; // 2MB
const file = e.target.files[0];
const chunks = [];
let start = 0;

while (start < file.size) {
  const end = Math.min(start + chunkSize, file.size);
  const chunk = file.slice(start, end);
  chunks.push(chunk);
  start = end;
}
```

2. **计算文件唯一标识（hash）**
```typescript
// 使用SparkMD5计算文件hash
import SparkMD5 from 'spark-md5';

async function calculateHash(file) {
  return new Promise((resolve) => {
    const spark = new SparkMD5.ArrayBuffer();
    const reader = new FileReader();
    const chunks = [];
    let currentChunk = 0;
    const chunkSize = 2 * 1024 * 1024;
    
    function loadNext() {
      const start = currentChunk * chunkSize;
      const end = Math.min(start + chunkSize, file.size);
      reader.readAsArrayBuffer(file.slice(start, end));
    }
    
    reader.onload = (e) => {
      spark.append(e.target.result);
      currentChunk++;
      
      if (currentChunk < Math.ceil(file.size / chunkSize)) {
        loadNext();
      } else {
        resolve(spark.end());
      }
    };
    
    loadNext();
  });
}
```

3. **上传前验证（秒传）**
```typescript
// 验证文件是否已存在
async function verifyUpload(fileHash, fileName) {
  const { data } = await axios.post('/api/upload/verify', {
    fileHash,
    fileName
  });
  return data;
}
```

4. **并行上传分片**
```typescript
// 上传分片
async function uploadChunks(chunks, fileHash, fileName, uploadedList = []) {
  const requests = chunks
    .filter((_, index) => !uploadedList.includes(index)) // 过滤已上传的分片
    .map((chunk, index) => {
      const formData = new FormData();
      formData.append('chunk', chunk);
      formData.append('hash', fileHash);
      formData.append('filename', fileName);
      formData.append('chunkIndex', index);
      
      return axios.post('/api/upload/chunk', formData, {
        onUploadProgress: (e) => {
          // 更新上传进度
        }
      });
    });
    
  return Promise.all(requests);
}
```

5. **请求合并分片**
```typescript
// 合并请求
async function mergeRequest(fileHash, fileName, size) {
  const { data } = await axios.post('/api/upload/merge', {
    fileHash,
    fileName,
    size
  });
  return data;
}
```

### 完整上传过程

```typescript
async function handleUpload() {
  const fileHash = await calculateHash(file);
  const { uploaded, uploadedList } = await verifyUpload(fileHash, file.name);
  
  if (uploaded) {
    // 文件已存在，秒传成功
    return;
  }
  
  // 分片上传
  const chunks = createFileChunks(file);
  await uploadChunks(chunks, fileHash, file.name, uploadedList);
  
  // 请求合并
  await mergeRequest(fileHash, file.name, file.size);
}
```

## 后端实现（mall-server）

### 技术选型
- 使用 `Node.js` 或 `Java` 作为后端语言
- 使用 `multer`（Node.js）或 `commons-fileupload`（Java）处理文件上传
- 使用 `fs-extra`（Node.js）或 `File API`（Java）进行文件操作

### 实现步骤（以Node.js为例）

1. **验证接口**
```javascript
// 验证文件是否已存在
router.post('/verify', async (req, res) => {
  const { fileHash, fileName } = req.body;
  const filePath = path.resolve(UPLOAD_DIR, fileHash); // UPLOAD_DIR为上传目录
  
  // 验证文件是否已存在
  if (fs.existsSync(filePath)) {
    return res.json({
      success: true,
      uploaded: true
    });
  }
  
  // 获取已上传的分片列表
  const uploadedList = await getUploadedChunks(fileHash);
  
  res.json({
    success: true,
    uploaded: false,
    uploadedList
  });
});

// 获取已上传的分片
async function getUploadedChunks(fileHash) {
  const chunksDir = path.resolve(UPLOAD_DIR, 'chunks', fileHash);
  if (!fs.existsSync(chunksDir)) {
    return [];
  }
  
  const files = await fs.readdir(chunksDir);
  return files.map(file => parseInt(file.split('-')[1]));
}
```

2. **分片上传接口**
```javascript
// 上传分片
router.post('/chunk', upload.single('chunk'), async (req, res) => {
  const { hash: fileHash, filename, chunkIndex } = req.body;
  const chunksDir = path.resolve(UPLOAD_DIR, 'chunks', fileHash);
  
  // 创建分片目录
  if (!fs.existsSync(chunksDir)) {
    await fs.mkdir(chunksDir, { recursive: true });
  }
  
  // 分片文件路径
  const chunkPath = path.resolve(chunksDir, `chunk-${chunkIndex}`);
  
  // 保存分片
  await fs.rename(req.file.path, chunkPath);
  
  res.json({
    success: true,
    message: '分片上传成功'
  });
});
```

3. **合并分片接口**
```javascript
// 合并分片
router.post('/merge', async (req, res) => {
  const { fileHash, fileName, size } = req.body;
  const chunksDir = path.resolve(UPLOAD_DIR, 'chunks', fileHash);
  const filePath = path.resolve(UPLOAD_DIR, fileHash);
  
  // 获取所有分片
  const chunks = await fs.readdir(chunksDir);
  
  // 按照索引排序
  chunks.sort((a, b) => {
    return parseInt(a.split('-')[1]) - parseInt(b.split('-')[1]);
  });
  
  // 合并分片
  await mergeChunks(chunks, chunksDir, filePath);
  
  // 保存文件信息到数据库
  // ...
  
  res.json({
    success: true,
    url: `/uploads/${fileHash}`, // 文件路径
    message: '文件上传成功'
  });
});

// 合并分片的方法
async function mergeChunks(chunks, chunksDir, filePath) {
  // 创建写入流
  const writeStream = fs.createWriteStream(filePath);
  
  for (const chunk of chunks) {
    const chunkPath = path.resolve(chunksDir, chunk);
    // 创建读取流
    const readStream = fs.createReadStream(chunkPath);
    // 管道连接
    await new Promise((resolve) => {
      readStream.pipe(writeStream, { end: false });
      readStream.on('end', resolve);
    });
    // 删除分片
    await fs.unlink(chunkPath);
  }
  
  // 关闭写入流
  writeStream.end();
  
  // 删除分片目录
  await fs.rmdir(chunksDir);
}
```

## 关键注意事项

1. **分片大小选择**
   - 太小：请求数量增多，服务器压力大
   - 太大：单个请求时间长，失败风险高
   - 推荐：2MB ~ 5MB

2. **并发数控制**
   - 浏览器对同域名并发请求有限制（通常为6-8个）
   - 建议控制并发数在3-5个

3. **错误处理**
   - 实现分片上传失败后的重试机制
   - 给用户提供手动重试选项

4. **安全考虑**
   - 验证文件类型和大小
   - 限制上传速率和文件大小
   - 服务器端进行文件安全扫描

5. **性能优化**
   - 使用Web Worker计算文件hash，避免阻塞主线程
   - 分片上传采用并发控制
   - 服务端使用流式处理，减少内存占用

## 后续扩展

1. **上传进度可视化**：提供整体和分片级别的进度条
2. **拖拽上传**：支持拖拽文件到指定区域上传
3. **多文件上传**：同时处理多个文件的上传
4. **限速功能**：控制上传带宽
5. **预览功能**：上传完成后提供文件预览

---

以上方案可根据具体业务需求和项目特点进行调整和优化。 

## 断点续传详细实现

### 什么是断点续传？

断点续传是指在文件上传过程中，如果因为网络问题、浏览器崩溃或用户主动暂停等原因导致上传中断，可以从中断的位置继续上传，而不必重新上传整个文件的技术。

### 为什么需要断点续传？

1. **节省时间和网络资源**：避免因中断而重新上传整个文件
2. **提升用户体验**：特别是大文件上传时，中断后不必从头开始
3. **应对网络不稳定场景**：在网络波动频繁的环境下更为实用

### 断点续传的基本原理

断点续传的核心原理很简单：**将大文件分割成多个小块，分别上传，并记录已上传的部分，中断后只上传未完成的部分**。

### 实现断点续传的详细步骤

#### 前端部分：

1. **文件分片**：
   ```javascript
   // 分片大小通常为 2MB~5MB
   const chunkSize = 2 * 1024 * 1024; // 2MB
   const file = input.files[0];
   const chunks = [];
   
   // 切割文件
   let start = 0;
   while (start < file.size) {
     const end = Math.min(start + chunkSize, file.size);
     const chunk = file.slice(start, end);
     chunks.push(chunk);
     start = end;
   }
   ```

2. **生成文件标识**：
   - 使用文件名、大小等信息作为标识
   - 更可靠的方法是计算文件的哈希值（如MD5），但计算大文件哈希可能耗时较长

3. **上传前检查**：
   - 向服务器发送文件标识，查询已上传的分片
   - 接收服务器返回的已上传分片列表
   ```javascript
   // 检查已上传的分片
   const checkExistingChunks = async (fileName, totalChunks) => {
     const response = await axios.post('/api/upload/verify', {
       filename: fileName,
       totalChunks
     });
     
     if (response.data.code === 200) {
       return response.data.data.uploadedChunks || [];
     }
     return [];
   };
   ```

4. **上传分片**：
   - 跳过已上传的分片，只上传未上传的部分
   - 可以顺序上传，也可以并发上传多个分片
   ```javascript
   // 上传单个分片
   const uploadChunk = async (chunk, index, fileName) => {
     const formData = new FormData();
     formData.append('chunk', chunk);
     formData.append('index', index);
     formData.append('filename', fileName);
     formData.append('totalChunks', chunks.length);
     
     const response = await axios.post('/api/upload/chunk', formData);
     return response.data.code === 200;
   };
   
   // 上传所有分片（跳过已上传的）
   const uploadChunks = async (chunks, fileName, existingChunks = []) => {
     for (let i = 0; i < chunks.length; i++) {
       // 跳过已上传的分片
       if (existingChunks.includes(i)) {
         console.log(`分片 ${i} 已上传，跳过`);
         continue;
       }
       
       await uploadChunk(chunks[i], i, fileName);
     }
   };
   ```

5. **合并请求**：
   - 所有分片上传完成后，发送合并请求
   ```javascript
   // 请求合并文件
   const mergeFile = async (fileName, totalChunks) => {
     const response = await axios.post('/api/upload/merge', {
       filename: fileName,
       totalChunks
     });
     return response.data;
   };
   ```

6. **上传状态管理**：
   - 记录上传进度
   - 实现暂停/继续功能
   - 处理刷新页面后的恢复上传

#### 后端部分：

1. **分片接收与存储**：
   ```javascript
   // 接收分片
   app.post('/api/upload/chunk', upload.single('chunk'), (req, res) => {
     const { index, filename, totalChunks } = req.body;
     
     // 验证参数
     if (!index || !filename || !totalChunks) {
       return res.status(400).json({ error: '参数不完整' });
     }
     
     // 存储分片
     const chunkDir = path.join(uploadDir, `chunks/${filename}`);
     if (!fs.existsSync(chunkDir)) {
       fs.mkdirSync(chunkDir, { recursive: true });
     }
     
     // 将分片保存到以索引命名的文件
     const chunkPath = path.join(chunkDir, index.toString());
     fs.renameSync(req.file.path, chunkPath);
     
     res.json({ code: 200, message: '分片上传成功' });
   });
   ```

2. **查询已上传分片**：
   ```javascript
   // 验证已上传分片
   app.post('/api/upload/verify', (req, res) => {
     const { filename, totalChunks } = req.body;
     
     if (!filename || !totalChunks) {
       return res.status(400).json({ error: '参数不完整' });
     }
     
     const chunkDir = path.join(uploadDir, `chunks/${filename}`);
     const uploadedChunks = [];
     
     // 检查分片目录是否存在
     if (fs.existsSync(chunkDir)) {
       const files = fs.readdirSync(chunkDir);
       
       // 检查每个分片的状态
       for (let i = 0; i < parseInt(totalChunks); i++) {
         if (files.includes(i.toString())) {
           uploadedChunks.push(i);
         }
       }
     }
     
     res.json({
       code: 200,
       data: { uploadedChunks }
     });
   });
   ```

3. **合并分片**：
   ```javascript
   // 合并分片
   app.post('/api/upload/merge', (req, res) => {
     const { filename, totalChunks } = req.body;
     
     if (!filename || !totalChunks) {
       return res.status(400).json({ error: '参数不完整' });
     }
     
     const chunkDir = path.join(uploadDir, `chunks/${filename}`);
     
     // 检查分片是否全部上传完成
     const files = fs.readdirSync(chunkDir);
     const validFiles = files.filter(file => {
       const index = parseInt(file);
       return !isNaN(index) && index >= 0 && index < parseInt(totalChunks);
     });
     
     if (validFiles.length !== parseInt(totalChunks)) {
       return res.json({
         code: 400,
         message: `分片不完整，已上传 ${validFiles.length}/${totalChunks}`
       });
     }
     
     // 生成最终文件名
     const fileExt = path.extname(filename);
     const finalName = `${Date.now()}-${filename}`;
     const filePath = path.join(uploadDir, finalName);
     
     // 创建写入流
     const writeStream = fs.createWriteStream(filePath);
     
     // 按顺序合并分片
     for (let i = 0; i < parseInt(totalChunks); i++) {
       const chunkPath = path.join(chunkDir, i.toString());
       const chunkData = fs.readFileSync(chunkPath);
       writeStream.write(chunkData);
       // 删除分片
       fs.unlinkSync(chunkPath);
     }
     
     // 关闭写入流
     writeStream.end();
     
     // 删除分片目录
     fs.rmdirSync(chunkDir, { recursive: true });
     
     res.json({
       code: 200,
       message: '文件合并成功',
       url: `/uploads/${finalName}`
     });
   });
   ```

### 断点续传的进阶优化

1. **分片传输的安全性**：
   - 添加用户验证，确保只有授权用户可以上传
   - 对分片添加签名，防止恶意上传

2. **分片上传的并发控制**：
   - 限制并发数量（通常3-5个），避免过多请求压垮服务器
   - 实现优先级队列，失败的分片优先重试

3. **断点续传的持久化**：
   - 使用localStorage或IndexedDB保存上传状态，在页面刷新后依然可以恢复
   - 在服务器端设置分片的过期时间，定期清理未完成的上传

4. **上传进度可视化**：
   - 实现整体进度条和分片级别的进度显示
   - 展示预计剩余时间和上传速度

5. **网络自适应**：
   - 根据网络状况动态调整并发数和分片大小
   - 在网络条件差的情况下，自动降低分片大小

### 常见问题及解决方案

1. **分片乱序问题**：
   - 确保分片按照索引顺序合并
   - 在前端记录每个分片的索引，在后端严格按照索引排序

2. **临时文件管理**：
   - 设置定时任务清理长时间未完成的上传
   - 对每个用户设置存储空间限制

3. **大文件哈希计算**：
   - 使用Web Worker在后台计算，避免阻塞主线程
   - 使用抽样计算或分片计算，提高速度

4. **不同浏览器兼容性**：
   - 针对不同浏览器的File API差异做兼容处理
   - 对旧版浏览器提供回退方案

### 断点续传流程总结

1. **前期准备**：
   - 生成文件标识（名称或MD5）
   - 将文件分割成多个小块
   
2. **上传前检查**：
   - 向服务器发送查询请求，获取已上传分片
   - 判断是否可以秒传（文件已存在）
   
3. **分片上传**：
   - 跳过已上传的分片，继续上传未完成的部分
   - 支持暂停/继续操作
   
4. **上传后处理**：
   - 所有分片上传完成后，请求服务器合并
   - 服务器合并分片，删除临时文件
   
5. **异常处理**：
   - 上传失败时自动重试
   - 网络中断后能够恢复上传

## 基于文件哈希的优化

当前的断点续传实现基于文件名作为唯一标识，这有一些局限性：

### 当前实现（基于文件名）的局限性

1. **不支持秒传**：无法识别完全相同但名称不同的文件
2. **唯一性不足**：不同文件可能具有相同的名称，导致混淆
3. **安全性较低**：无法验证文件内容的完整性和一致性

### 为什么需要添加哈希

添加文件哈希（如MD5）可以实现：

1. **文件秒传**：通过哈希值检查服务器是否已有相同文件，有则直接标记为上传成功
2. **内容唯一标识**：哈希值基于文件内容生成，提供更可靠的唯一标识
3. **完整性校验**：可以验证分片和最终文件的完整性，避免损坏

### 实现哈希的方法

要添加哈希支持，可以这样实现：

```javascript
// 前端计算文件哈希
import SparkMD5 from 'spark-md5';

async function calculateFileHash(file) {
  return new Promise(resolve => {
    const spark = new SparkMD5.ArrayBuffer();
    const reader = new FileReader();
    const chunkSize = 2 * 1024 * 1024;
    let currentChunk = 0;
    const chunks = Math.ceil(file.size / chunkSize);
    
    reader.onload = e => {
      spark.append(e.target.result);
      currentChunk++;
      
      if (currentChunk < chunks) {
        loadNext();
      } else {
        resolve(spark.end()); // 返回MD5哈希值
      }
    };
    
    function loadNext() {
      const start = currentChunk * chunkSize;
      const end = Math.min(start + chunkSize, file.size);
      reader.readAsArrayBuffer(file.slice(start, end));
    }
    
    loadNext();
  });
}
```

### 如何改进当前实现

如果要添加哈希支持，您可以：

1. 在前端添加文件哈希计算（使用Web Worker避免阻塞主线程）
2. 修改后端接口，支持基于哈希的文件验证
3. 实现文件秒传功能：如果服务器已有相同哈希的文件，直接返回成功

这是断点续传的进阶功能，可以在基础功能稳定后添加。 